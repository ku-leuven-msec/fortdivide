diff -ur orig/arch/x86/entry/syscalls/syscall_64.tbl linux-source-5.4.0/arch/x86/entry/syscalls/syscall_64.tbl
--- orig/arch/x86/entry/syscalls/syscall_64.tbl	2023-01-06 13:39:51.898475202 +0100
+++ linux-source-5.4.0/arch/x86/entry/syscalls/syscall_64.tbl	2023-01-06 14:54:42.371625106 +0100
@@ -364,6 +364,8 @@
 # on-the-fly for compat_sys_*() compatibility system calls if X86_X32
 # is defined.
 #
+509	common	pmvee_switch	__x64_sys_pmvee_switch
+510	common	pmvee_check 	__x64_sys_pmvee_check
 512	x32	rt_sigaction		__x32_compat_sys_rt_sigaction
 513	x32	rt_sigreturn		sys32_x32_rt_sigreturn
 514	x32	ioctl			__x32_compat_sys_ioctl
Only in linux-source-5.4.0/: .git
diff -ur orig/kernel/events/uprobes.c linux-source-5.4.0/kernel/events/uprobes.c
--- orig/kernel/events/uprobes.c	2022-11-23 21:19:00.000000000 +0100
+++ linux-source-5.4.0/kernel/events/uprobes.c	2023-01-06 14:54:42.371625106 +0100
@@ -1569,11 +1569,13 @@
 {
 	percpu_down_read(&dup_mmap_sem);
 }
+EXPORT_SYMBOL(uprobe_start_dup_mmap);
 
 void uprobe_end_dup_mmap(void)
 {
 	percpu_up_read(&dup_mmap_sem);
 }
+EXPORT_SYMBOL(uprobe_end_dup_mmap);
 
 void uprobe_dup_mmap(struct mm_struct *oldmm, struct mm_struct *newmm)
 {
@@ -1583,6 +1585,7 @@
 		set_bit(MMF_RECALC_UPROBES, &newmm->flags);
 	}
 }
+EXPORT_SYMBOL(uprobe_dup_mmap);
 
 /*
  *  - search for a free slot.
diff -ur orig/kernel/fork.c linux-source-5.4.0/kernel/fork.c
--- orig/kernel/fork.c	2022-11-23 21:19:00.000000000 +0100
+++ linux-source-5.4.0/kernel/fork.c	2023-01-06 14:54:42.372625110 +0100
@@ -366,6 +366,7 @@
 	}
 	return new;
 }
+EXPORT_SYMBOL(vm_area_dup);
 
 void vm_area_free(struct vm_area_struct *vma)
 {
diff -ur orig/kernel/sys.c linux-source-5.4.0/kernel/sys.c
--- orig/kernel/sys.c	2022-11-23 21:19:00.000000000 +0100
+++ linux-source-5.4.0/kernel/sys.c	2023-01-06 14:54:42.372625110 +0100
@@ -2228,6 +2228,35 @@
 	return error;
 }
 
+
+long (*pmvee_switch_stub) (pid_t leader, unsigned long from, unsigned long size_one, unsigned long size_two, unsigned long flags) = NULL;
+EXPORT_SYMBOL(pmvee_switch_stub);
+
+SYSCALL_DEFINE5(pmvee_switch, pid_t, leader, unsigned long, from, unsigned long, size_one, unsigned long, size_two, unsigned long, flags)
+{
+	if (pmvee_switch_stub)
+		return pmvee_switch_stub(leader, from, size_one, size_two, flags);
+	else
+		printk("system call pmvee_switch not implemented.\n");
+
+	return ENOSYS;
+}
+
+
+long (*pmvee_check_stub) (pid_t leader, unsigned long from, unsigned long size_one, unsigned long size_two, unsigned long flags) = NULL;
+EXPORT_SYMBOL(pmvee_check_stub);
+
+SYSCALL_DEFINE5(pmvee_check, pid_t, leader, unsigned long, from, unsigned long, size_one, unsigned long, size_two, unsigned long, flags)
+{
+	if (pmvee_check_stub)
+		return pmvee_check_stub(leader, from, size_one, size_two, flags);
+	else
+		printk("system call pmvee_check not implemented.\n");
+
+	return ENOSYS;
+}
+
+
 #ifdef CONFIG_CHECKPOINT_RESTORE
 static int prctl_get_tid_address(struct task_struct *me, int __user **tid_addr)
 {
diff -ur orig/mm/mmap.c linux-source-5.4.0/mm/mmap.c
--- orig/mm/mmap.c	2023-01-09 15:21:00.373778461 +0100
+++ linux-source-5.4.0/mm/mmap.c	2022-11-23 21:19:00.000000000 +0100
@@ -132,7 +132,6 @@
 	/* remove_protection_ptes reads vma->vm_page_prot without mmap_sem */
 	WRITE_ONCE(vma->vm_page_prot, vm_page_prot);
 }
+EXPORT_SYMBOL(vma_set_page_prot);
 
 /*
  * Requires inode->i_mapping->i_mmap_rwsem
@@ -609,7 +608,6 @@
 	vma_gap_update(vma);
 	vma_rb_insert(vma, &mm->mm_rb);
 }
+EXPORT_SYMBOL(__vma_link_rb);
 
 static void __vma_link_file(struct vm_area_struct *vma)
 {
@@ -2862,7 +2860,6 @@
 
 	return downgrade ? 1 : 0;
 }
+EXPORT_SYMBOL(__do_munmap);
 
 int do_munmap(struct mm_struct *mm, unsigned long start, size_t len,
 	      struct list_head *uf)
diff -ur orig/mm/rmap.c linux-source-5.4.0/mm/rmap.c
--- orig/mm/rmap.c	2022-11-23 21:19:00.000000000 +0100
+++ linux-source-5.4.0/mm/rmap.c	2023-01-06 14:54:42.373625113 +0100
@@ -381,6 +381,7 @@
 	unlink_anon_vmas(vma);
 	return -ENOMEM;
 }
+EXPORT_SYMBOL(anon_vma_fork);
 
 void unlink_anon_vmas(struct vm_area_struct *vma)
 {
diff -ur orig/arch/x86/mm/tlb.c linux-source-5.4.0/arch/x86/mm/tlb.c 
--- orig/arch/x86/mm/tlb.c	2023-01-09 14:49:50.596258910 +0100
+++ linux-source-5.4.0/arch/x86/mm/tlb.c	2022-11-23 21:19:00.000000000 +0100
@@ -806,7 +806,6 @@
 	put_flush_tlb_info();
 	put_cpu();
 }
+EXPORT_SYMBOL(flush_tlb_mm_range);
 
 
 static void do_flush_tlb_all(void *info)
diff -ur orig/mm/memory.c linux-source-5.4.0/mm/memory.c 
--- orig/mm/memory.c	2023-01-09 14:50:16.096260703 +0100
+++ linux-source-5.4.0/mm/memory.c	2022-11-23 21:19:00.000000000 +0100
@@ -1012,7 +1012,6 @@
 		mmu_notifier_invalidate_range_end(&range);
 	return ret;
 }
+EXPORT_SYMBOL(copy_page_range);
 
 /* Whether we should zap all COWed (private) pages too */
 static inline bool should_zap_cows(struct zap_details *details)
diff -ur orig/mm/mprotect.c linux-source-5.4.0/mm/mprotect.c 
--- orig/mm/mprotect.c	2023-01-09 15:21:18.085799104 +0100
+++ linux-source-5.4.0/mm/mprotect.c	2022-11-23 21:19:00.000000000 +0100
@@ -327,7 +327,6 @@
 
 	return pages;
 }
+EXPORT_SYMBOL(change_protection);
 
 unsigned long change_protection(struct vm_area_struct *vma, unsigned long start,
 		       unsigned long end, pgprot_t newprot,
diff -ur orig/mm/interval_tree.c linux-source-5.4.0/mm/interval_tree.c
--- orig/mm/interval_tree.c    2023-01-24 17:04:29.471654623 +0100
+++ linux-source-5.4.0/mm/interval_tree.c  2023-01-24 17:05:32.064768057 +0100
@@ -57,6 +57,7 @@
        rb_insert_augmented(&node->shared.rb, &root->rb_root,
                            &vma_interval_tree_augment);
 }
+EXPORT_SYMBOL(vma_interval_tree_insert_after);
 
 static inline unsigned long avc_start_pgoff(struct anon_vma_chain *avc)
 {
diff -ur orig/mm/prfile.c linux-source-5.4.0/mm/prfile.c
--- orig/mm/prfile.c   2023-01-24 17:04:27.280645615 +0100
+++ linux-source-5.4.0/mm/prfile.c 2023-01-24 17:05:16.215801167 +0100
@@ -53,6 +53,7 @@
        if (f && pr)
                get_file(pr);
 }
+EXPORT_SYMBOL(vma_do_get_file);
 
 void vma_do_fput(struct vm_area_struct *vma, const char func[], int line)
 {
