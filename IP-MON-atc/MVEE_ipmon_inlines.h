#ifndef IPMON_INLINES_H_
#define IPMON_INLINES_H_

/*
 * For each of these inline assembly function has possible different variants, potentially one for each combination of pointer-arguments:
 * - pointer argument points to local memory (i.e., not into the RB) and thus can leak
 * - pointer argument would point into the RB and should not leak. Thus, this argument is now an *offset* into the RB, through the
 *   RB_REGISTER register.
 * 
 * These functions (only those currently used in IP-MON are implemented) have different names, depending on their arguments:
 * - local pointers get _localptr as a suffix to their name;
 * - RB offset-using functions get _offset.
 * Functions with two pointer arguments get a combined suffix, e.g., memcmp_offset_ptr. The pointer-variants are the 'original' ones,
 * i.e., those copied from an external source.
 * 
 * NOTE: some functions return one of their arguments, for example, memcpy returns a pointer to dst. By definition, memcpy_offset_ptr CANNOT
 * return (i.e., leak) the dst pointer, and hence such functions return VOID instead!
 */

#include <stdlib.h>

/*-----------------------------------------------------------------------------
    strlen
-----------------------------------------------------------------------------*/

/* From http://kam.mff.cuni.cz/~ondra/benchmark_string/core2/strlen_profile/variant/strlen_revised.s */

STATIC INLINE size_t ipmon_strlen_ptr(const char* str)
{
	size_t result;

	asm volatile ("pxor %%xmm8, %%xmm8\n\t"
		"pxor %%xmm9, %%xmm9\n\t"
		"pxor %%xmm10, %%xmm10\n\t"
		"pxor %%xmm11, %%xmm11\n\t"
		"movq %[str], %%rax\n\t"
		"movq %[str], %%rcx\n\t"
		"andq $4095, %%rcx\n\t"
		"cmpq $4047, %%rcx\n\t"
		"ja 2f\n\t"
		"movdqu (%%rax), %%xmm12\n\t"
		"pcmpeqb %%xmm8, %%xmm12\n\t"
		"pmovmskb %%xmm12, %%edx\n\t"
		"test %%edx, %%edx\n\t"
		"je 1f\n\t"
		"bsfq %%rdx, %%rax\n\t"
		"jmp 5f\n\t"
		"1:\n\t"
		"andq $-16, %%rax\n\t"
		"pcmpeqb 16(%%rax), %%xmm9;\n\t"
		"pcmpeqb 32(%%rax), %%xmm10;\n\t"
		"pcmpeqb 48(%%rax), %%xmm11;\n\t"
		"pmovmskb %%xmm9, %%edx;\n\t"
		"pmovmskb %%xmm10, %%r8d;\n\t"
		"pmovmskb %%xmm11, %%ecx;\n\t"
		"salq $16, %%rdx;\n\t"
		"salq $16, %%rcx;\n\t"
		"orq %%r8, %%rcx;\n\t"
		"salq $32, %%rcx;\n\t"
		"orq %%rcx, %%rdx;\n\t"
		"movq %[str], %%rcx\n\t"
		"xorq %%rax, %%rcx\n\t"
		"andq $-64, %%rax\n\t"
		"sarq %%cl, %%rdx\n\t"
		"test %%rdx, %%rdx\n\t"
		"je 3f\n\t"
		"bsfq %%rdx, %%rax\n\t"
		"jmp 5f\n\t"
		".p2align 4\n\t"
		"2:\n\t"
		"andq $-64, %%rax\n\t"
		"pcmpeqb (%%rax), %%xmm8\n\t"
		"pcmpeqb 16(%%rax), %%xmm9\n\t"
		"pcmpeqb 32(%%rax), %%xmm10\n\t"
		"pcmpeqb 48(%%rax), %%xmm11\n\t"
		"pmovmskb %%xmm8, %%esi\n\t"
		"pmovmskb %%xmm9, %%edx\n\t"
		"pmovmskb %%xmm10, %%r8d\n\t"
		"pmovmskb %%xmm11, %%ecx\n\t"
		"salq $16, %%rdx\n\t"
		"salq $16, %%rcx\n\t"
		"orq %%rsi, %%rdx\n\t"
		"orq %%r8, %%rcx\n\t"
		"salq $32, %%rcx\n\t"
		"orq %%rcx, %%rdx\n\t"
		"movq %[str], %%rcx\n\t"
		"xorq %%rax, %%rcx\n\t"
		"andq $-64, %%rax\n\t"
		"sarq %%cl, %%rdx\n\t"
		"test %%rdx, %%rdx\n\t"
		"je 4f\n\t"
		"bsfq %%rdx, %%rax\n\t"
		"jmp 5f\n\t"
		".p2align 4\n\t"
		"4:\n\t"
		"pxor %%xmm9, %%xmm9\n\t"
		"pxor %%xmm10, %%xmm10\n\t"
		"pxor %%xmm11, %%xmm11\n\t"
		".p2align 4\n\t"
		"3:\n\t"
		"movdqa 64(%%rax), %%xmm8\n\t"
		"pminub 80(%%rax), %%xmm8\n\t"
		"pminub 96(%%rax), %%xmm8\n\t"
		"pminub 112(%%rax), %%xmm8\n\t"
		"pcmpeqb %%xmm11, %%xmm8\n\t"
		"pmovmskb %%xmm8, %%edx\n\t"
		"testl %%edx, %%edx\n\t"
		"jne 6f\n\t"
		"subq $-128, %%rax\n\t"
		"movdqa (%%rax), %%xmm8\n\t"
		"pminub 16(%%rax), %%xmm8\n\t"
		"pminub 32(%%rax), %%xmm8\n\t"
		"pminub 48(%%rax), %%xmm8\n\t"
		"pcmpeqb %%xmm11, %%xmm8\n\t"
		"pmovmskb %%xmm8, %%edx\n\t"
		"testl %%edx, %%edx\n\t"
		"jne 7f\n\t"
		"jmp 3b\n\t"
		".p2align 4\n\t"
		"6:\n\t"
		"addq $64, %%rax\n\t"
		"7:\n\t"
		"pxor %%xmm8, %%xmm8\n\t"
		"pcmpeqb (%%rax), %%xmm8\n\t"
		"pcmpeqb 16(%%rax), %%xmm9\n\t"
		"pcmpeqb 32(%%rax), %%xmm10\n\t"
		"pcmpeqb 48(%%rax), %%xmm11\n\t"
		"pmovmskb %%xmm8, %%esi\n\t"
		"pmovmskb %%xmm9, %%edx\n\t"
		"pmovmskb %%xmm10, %%r8d\n\t"
		"pmovmskb %%xmm11, %%ecx\n\t"
		"salq $16, %%rdx\n\t"
		"salq $16, %%rcx\n\t"
		"orq %%rsi, %%rdx\n\t"
		"orq %%r8, %%rcx\n\t"
		"salq $32, %%rcx\n\t"
		"orq %%rcx, %%rdx\n\t"
		"bsfq %%rdx, %%rdx\n\t"
		"addq %%rdx, %%rax\n\t"
		"subq %[str], %%rax\n\t"
		"5:\n\t"
		"movq %%rax, %[result]\n\t"
		:[result] "=r"(result)	/* output operand */
		:[str] "r"(str)		/* input operand */
		:"cc", "memory", "%xmm8", "%xmm9", "%xmm10", "%xmm11", "%xmm12", "%rax", "%rcx", "%edx", "%r8", "%ecx", "%rdx", "%esi"
		);

	return (result);
}

/*-----------------------------------------------------------------------------
    memcpy
-----------------------------------------------------------------------------*/

/* From http://kam.mff.cuni.cz/~ondra/benchmark_string/core2/memcpy_profile/variant/memcpy-sse2-unaligned.s */

STATIC INLINE void * ipmon_memcpy_ptr_ptr(void* destination, const void* source, size_t num)
{
	asm volatile("movq %[destination], %%rdi\n\t"
		"movq %[source], %%rsi\n\t"
		"movq %[num], %%rdx\n\t"
		"movq %%rsi, %%rax\n\t"
		"leaq (%%rdx,%%rdx), %%rcx\n\t"
		"subq %%rdi, %%rax\n\t"
		"subq %%rdx, %%rax\n\t"
		"cmpq %%rcx, %%rax\n\t"
		"jb 8f\n\t"
		"cmpq $16, %%rdx\n\t"
		"jbe 9f\n\t"
		"movdqu (%%rsi), %%xmm8\n\t"
		"cmpq $32, %%rdx\n\t"
		"movdqu %%xmm8, (%%rdi)\n\t"
		"movdqu -16(%%rsi,%%rdx), %%xmm8\n\t"
		"movdqu %%xmm8, -16(%%rdi,%%rdx)\n\t"
		"ja 10f\n\t"
		"11:\n\t"
		"movq %%rdi, %%rax\n\t"
		"jmp 20f\n\t"
		".p2align 4,,10\n\t"
		".p2align 4\n\t"
		"10:\n\t"
		"movdqu 16(%%rsi), %%xmm8\n\t"
		"cmpq $64, %%rdx\n\t"
		"movdqu %%xmm8, 16(%%rdi)\n\t"
		"movdqu -32(%%rsi,%%rdx), %%xmm8\n\t"
		"movdqu %%xmm8, -32(%%rdi,%%rdx)\n\t"
		"jbe 11b\n\t"
		"movdqu 32(%%rsi), %%xmm8\n\t"
		"cmpq $128, %%rdx\n\t"
		"movdqu %%xmm8, 32(%%rdi)\n\t"
		"movdqu -48(%%rsi,%%rdx), %%xmm8\n\t"
		"movdqu %%xmm8, -48(%%rdi,%%rdx)\n\t"
		"movdqu 48(%%rsi), %%xmm8\n\t"
		"movdqu %%xmm8, 48(%%rdi)\n\t"
		"movdqu -64(%%rsi,%%rdx), %%xmm8\n\t"
		"movdqu %%xmm8, -64(%%rdi,%%rdx)\n\t"
		"jbe 11b\n\t"
		"leaq 64(%%rdi), %%rcx\n\t"
		"addq %%rdi, %%rdx\n\t"
		"andq $-64, %%rdx\n\t"
		"andq $-64, %%rcx\n\t"
		"movq %%rcx, %%rax\n\t"
		"subq %%rdi, %%rax\n\t"
		"addq %%rax, %%rsi\n\t"
		"cmpq %%rdx, %%rcx\n\t"
		"je 11b\n\t"
		"movq %%rsi, %%r10\n\t"
		"subq %%rcx, %%r10\n\t"
		"leaq 16(%%r10), %%r9\n\t"
		"leaq 32(%%r10), %%r8\n\t"
		"leaq 48(%%r10), %%rax\n\t"
		".p2align 4,,10\n\t"
		".p2align 4\n\t"
		"12:\n\t"
		"movdqu (%%rcx,%%r10), %%xmm8\n\t"
		"movdqa %%xmm8, (%%rcx)\n\t"
		"movdqu (%%rcx,%%r9), %%xmm8\n\t"
		"movdqa %%xmm8, 16(%%rcx)\n\t"
		"movdqu (%%rcx,%%r8), %%xmm8\n\t"
		"movdqa %%xmm8, 32(%%rcx)\n\t"
		"movdqu (%%rcx,%%rax), %%xmm8\n\t"
		"movdqa %%xmm8, 48(%%rcx)\n\t"
		"addq $64, %%rcx\n\t"
		"cmpq %%rcx, %%rdx\n\t"
		"jne 12b\n\t"
		"jmp 11b\n\t"
		"8:\n\t"
		"cmpq %%rsi, %%rdi\n\t"
		"jae 13f\n\t"
		"testq %%rdx, %%rdx\n\t"
		".p2align 4,,5\n\t"
		"je 11b\n\t"
		"movq %%rdx, %%r9\n\t"
		"leaq 16(%%rsi), %%rcx\n\t"
		"leaq 16(%%rdi), %%r8\n\t"
		"shrq $4, %%r9\n\t"
		"movq %%r9, %%rax\n\t"
		"salq $4, %%rax\n\t"
		"cmpq %%rcx, %%rdi\n\t"
		"setae %%cl\n\t"
		"cmpq %%r8, %%rsi\n\t"
		"setae %%r8b\n\t"
		"orl %%r8d, %%ecx\n\t"
		"cmpq $15, %%rdx\n\t"
		"seta %%r8b\n\t"
		"testb %%r8b, %%cl\n\t"
		"je 19f\n\t"
		"testq %%rax, %%rax\n\t"
		"je 19f\n\t"
		"xorl %%ecx, %%ecx\n\t"
		"xorl %%r8d, %%r8d\n\t"
		"14:\n\t"
		"movdqu (%%rsi,%%rcx), %%xmm8\n\t"
		"addq $1, %%r8\n\t"
		"movdqu %%xmm8, (%%rdi,%%rcx)\n\t"
		"addq $16, %%rcx\n\t"
		"cmpq %%r8, %%r9\n\t"
		"ja 14b\n\t"
		"cmpq %%rax, %%rdx\n\t"
		"je 11b\n\t"
		"15:\n\t"
		"movzbl (%%rsi,%%rax), %%ecx\n\t"
		"movb %%cl, (%%rdi,%%rax)\n\t"
		"addq $1, %%rax\n\t"
		"cmpq %%rax, %%rdx\n\t"
		"ja 15b\n\t"
		"jmp 11b\n\t"
		"9:\n\t"
		"testb $24, %%dl\n\t"
		"jne 16f\n\t"
		"testb $4, %%dl\n\t"
		".p2align 4,,5\n\t"
		"jne 17f\n\t"
		"testq %%rdx, %%rdx\n\t"
		".p2align 4,,2\n\t"
		"je 11b\n\t"
		"movzbl (%%rsi), %%eax\n\t"
		"testb $2, %%dl\n\t"
		"movb %%al, (%%rdi)\n\t"
		"je 11b\n\t"
		"movzwl -2(%%rsi,%%rdx), %%eax\n\t"
		"movw %%ax, -2(%%rdi,%%rdx)\n\t"
		"jmp 11b\n\t"
		"13:\n\t"
		"leaq -1(%%rdx), %%rax\n\t"
		".p2align 4,,10\n\t"
		".p2align 4\n\t"
		"18:\n\t"
		"movzbl (%%rsi,%%rax), %%edx\n\t"
		"movb %%dl, (%%rdi,%%rax)\n\t"
		"subq $1, %%rax\n\t"
		"jmp 18b\n\t"
		"16:\n\t"
		"movq (%%rsi), %%rax\n\t"
		"movq %%rax, (%%rdi)\n\t"
		"movq -8(%%rsi,%%rdx), %%rax\n\t"
		"movq %%rax, -8(%%rdi,%%rdx)\n\t"
		"jmp 11b\n\t"
		"19:\n\t"
		"xorl %%eax, %%eax\n\t"
		"jmp 15b\n\t"
		"17:\n\t"
		"movl (%%rsi), %%eax\n\t"
		"movl %%eax, (%%rdi)\n\t"
		"movl -4(%%rsi,%%rdx), %%eax\n\t"
		"movl %%eax, -4(%%rdi,%%rdx)\n\t"
		"jmp 11b\n\t"
		"20:\n\t"
		"movq %%rax, %[destination]\n\t" // this may also be omitted, toDo
		:[destination] "+r"(destination) 	/* + means that destination is both input and output operand  */
		:[source] "r"(source), [num] "r"(num)	/* source and num are input operands */
		:"cc", "memory", "%rdi", "%rsi", "%rdx", "%rax", "%rcx", "%xmm8", "%r10", "%r9", "%r8", "%cl", "%ecx", "%dl", "%eax", "%edx"
	);

		return destination; // this may be omitted, toDo
}

/*---------------------------------------------------------------------------*/

STATIC INLINE void * ipmon_memcpy_ptr_offset(void* destination, unsigned long source_offset, size_t num)
{
	asm volatile("movq %[destination], %%rdi\n\t"
		"leaq (%%" RB_REGISTER ", %[source_offset]), %%rsi\n\t"		/* rsi tainted! */
		"movq %[num], %%rdx\n\t"
		"movq %%rsi, %%rax\n\t"
		"leaq (%%rdx,%%rdx), %%rcx\n\t"
		"subq %%rdi, %%rax\n\t"
		"subq %%rdx, %%rax\n\t"
		"cmpq %%rcx, %%rax\n\t"
		"jb 8f\n\t"
		"cmpq $16, %%rdx\n\t"
		"jbe 9f\n\t"
		"movdqu (%%rsi), %%xmm8\n\t"
		"cmpq $32, %%rdx\n\t"
		"movdqu %%xmm8, (%%rdi)\n\t"
		"movdqu -16(%%rsi,%%rdx), %%xmm8\n\t"
		"movdqu %%xmm8, -16(%%rdi,%%rdx)\n\t"
		"ja 10f\n\t"
		"11:\n\t"
		"movq %%rdi, %%rax\n\t"
		"jmp 20f\n\t"
		".p2align 4,,10\n\t"
		".p2align 4\n\t"
		"10:\n\t"
		"movdqu 16(%%rsi), %%xmm8\n\t"
		"cmpq $64, %%rdx\n\t"
		"movdqu %%xmm8, 16(%%rdi)\n\t"
		"movdqu -32(%%rsi,%%rdx), %%xmm8\n\t"
		"movdqu %%xmm8, -32(%%rdi,%%rdx)\n\t"
		"jbe 11b\n\t"
		"movdqu 32(%%rsi), %%xmm8\n\t"
		"cmpq $128, %%rdx\n\t"
		"movdqu %%xmm8, 32(%%rdi)\n\t"
		"movdqu -48(%%rsi,%%rdx), %%xmm8\n\t"
		"movdqu %%xmm8, -48(%%rdi,%%rdx)\n\t"
		"movdqu 48(%%rsi), %%xmm8\n\t"
		"movdqu %%xmm8, 48(%%rdi)\n\t"
		"movdqu -64(%%rsi,%%rdx), %%xmm8\n\t"
		"movdqu %%xmm8, -64(%%rdi,%%rdx)\n\t"
		"jbe 11b\n\t"
		"leaq 64(%%rdi), %%rcx\n\t"
		"addq %%rdi, %%rdx\n\t"
		"andq $-64, %%rdx\n\t"
		"andq $-64, %%rcx\n\t"
		"movq %%rcx, %%rax\n\t"
		"subq %%rdi, %%rax\n\t"
		"addq %%rax, %%rsi\n\t"
		"cmpq %%rdx, %%rcx\n\t"
		"je 11b\n\t"
		"movq %%rsi, %%r10\n\t"
		"subq %%rcx, %%r10\n\t"
		"leaq 16(%%r10), %%r9\n\t"
		"leaq 32(%%r10), %%r8\n\t"
		"leaq 48(%%r10), %%rax\n\t"
		".p2align 4,,10\n\t"
		".p2align 4\n\t"
		"12:\n\t"
		"movdqu (%%rcx,%%r10), %%xmm8\n\t"
		"movdqa %%xmm8, (%%rcx)\n\t"
		"movdqu (%%rcx,%%r9), %%xmm8\n\t"
		"movdqa %%xmm8, 16(%%rcx)\n\t"
		"movdqu (%%rcx,%%r8), %%xmm8\n\t"
		"movdqa %%xmm8, 32(%%rcx)\n\t"
		"movdqu (%%rcx,%%rax), %%xmm8\n\t"
		"movdqa %%xmm8, 48(%%rcx)\n\t"
		"addq $64, %%rcx\n\t"
		"cmpq %%rcx, %%rdx\n\t"
		"jne 12b\n\t"
		"jmp 11b\n\t"
		"8:\n\t"
		"cmpq %%rsi, %%rdi\n\t"
		"jae 13f\n\t"
		"testq %%rdx, %%rdx\n\t"
		".p2align 4,,5\n\t"
		"je 11b\n\t"
		"movq %%rdx, %%r9\n\t"
		"leaq 16(%%rsi), %%rcx\n\t"
		"leaq 16(%%rdi), %%r8\n\t"
		"shrq $4, %%r9\n\t"
		"movq %%r9, %%rax\n\t"
		"salq $4, %%rax\n\t"
		"cmpq %%rcx, %%rdi\n\t"
		"setae %%cl\n\t"
		"cmpq %%r8, %%rsi\n\t"
		"setae %%r8b\n\t"
		"orl %%r8d, %%ecx\n\t"
		"cmpq $15, %%rdx\n\t"
		"seta %%r8b\n\t"
		"testb %%r8b, %%cl\n\t"
		"je 19f\n\t"
		"testq %%rax, %%rax\n\t"
		"je 19f\n\t"
		"xorl %%ecx, %%ecx\n\t"
		"xorl %%r8d, %%r8d\n\t"
		"14:\n\t"
		"movdqu (%%rsi,%%rcx), %%xmm8\n\t"
		"addq $1, %%r8\n\t"
		"movdqu %%xmm8, (%%rdi,%%rcx)\n\t"
		"addq $16, %%rcx\n\t"
		"cmpq %%r8, %%r9\n\t"
		"ja 14b\n\t"
		"cmpq %%rax, %%rdx\n\t"
		"je 11b\n\t"
		"15:\n\t"
		"movzbl (%%rsi,%%rax), %%ecx\n\t"
		"movb %%cl, (%%rdi,%%rax)\n\t"
		"addq $1, %%rax\n\t"
		"cmpq %%rax, %%rdx\n\t"
		"ja 15b\n\t"
		"jmp 11b\n\t"
		"9:\n\t"
		"testb $24, %%dl\n\t"
		"jne 16f\n\t"
		"testb $4, %%dl\n\t"
		".p2align 4,,5\n\t"
		"jne 17f\n\t"
		"testq %%rdx, %%rdx\n\t"
		".p2align 4,,2\n\t"
		"je 11b\n\t"
		"movzbl (%%rsi), %%eax\n\t"
		"testb $2, %%dl\n\t"
		"movb %%al, (%%rdi)\n\t"
		"je 11b\n\t"
		"movzwl -2(%%rsi,%%rdx), %%eax\n\t"
		"movw %%ax, -2(%%rdi,%%rdx)\n\t"
		"jmp 11b\n\t"
		"13:\n\t"
		"leaq -1(%%rdx), %%rax\n\t"
		".p2align 4,,10\n\t"
		".p2align 4\n\t"
		"18:\n\t"
		"movzbl (%%rsi,%%rax), %%edx\n\t"
		"movb %%dl, (%%rdi,%%rax)\n\t"
		"subq $1, %%rax\n\t"
		"jmp 18b\n\t"
		"16:\n\t"
		"movq (%%rsi), %%rax\n\t"
		"movq %%rax, (%%rdi)\n\t"
		"movq -8(%%rsi,%%rdx), %%rax\n\t"
		"movq %%rax, -8(%%rdi,%%rdx)\n\t"
		"jmp 11b\n\t"
		"19:\n\t"
		"xorl %%eax, %%eax\n\t"
		"jmp 15b\n\t"
		"17:\n\t"
		"movl (%%rsi), %%eax\n\t"
		"movl %%eax, (%%rdi)\n\t"
		"movl -4(%%rsi,%%rdx), %%eax\n\t"
		"movl %%eax, -4(%%rdi,%%rdx)\n\t"
		"jmp 11b\n\t"
		"20:\n\t"
		"movq %%rax, %[destination]\n\t" // this may also be omitted, toDo
		/* scrub registers */
		/* TODO manually audit the above code to see which registers can contain the pointer and thus need to be scrubbed, rather than scrubbing them all */
		"xorq %%rdi, %%rdi\n"
		"xorq %%rsi, %%rsi\n"
		"xorq %%rdx, %%rdx\n"
		"xorq %%rcx, %%rcx\n"
		"pxor %%xmm8, %%xmm8\n"
		"xorq %%r10, %%r10\n"
		"xorq %%r9, %%r9\n"
		"xorq %%r8, %%r8\n"
		:[destination] "+r"(destination) 	/* + means that destination is both input and output operand  */
		:[source_offset] "r"(source_offset), [num] "r"(num)	/* source and num are input operands */
		:"cc", "memory", "%rdi", "%rsi", "%rdx", "%rax", "%rcx", "%xmm8", "%r10", "%r9", "%r8", "%cl", "%ecx", "%dl", "%eax", "%edx"
	);

		return destination; // this may be omitted, toDo
}

/*---------------------------------------------------------------------------*/

/* NOTE: returns void rather than void* ! */

STATIC INLINE void ipmon_memcpy_offset_ptr(unsigned long destination_offset, const void* source, size_t num)
{
	asm volatile("leaq (%%" RB_REGISTER ", %[destination_offset]), %%rdi\n\t"	/* rdi tainted! */
		"movq %[source], %%rsi\n\t"
		"movq %[num], %%rdx\n\t"
		"movq %%rsi, %%rax\n\t"
		"leaq (%%rdx,%%rdx), %%rcx\n\t"
		"subq %%rdi, %%rax\n\t"
		"subq %%rdx, %%rax\n\t"
		"cmpq %%rcx, %%rax\n\t"
		"jb 8f\n\t"
		"cmpq $16, %%rdx\n\t"
		"jbe 9f\n\t"
		"movdqu (%%rsi), %%xmm8\n\t"
		"cmpq $32, %%rdx\n\t"
		"movdqu %%xmm8, (%%rdi)\n\t"
		"movdqu -16(%%rsi,%%rdx), %%xmm8\n\t"
		"movdqu %%xmm8, -16(%%rdi,%%rdx)\n\t"
		"ja 10f\n\t"
		"11:\n\t"
		"movq %%rdi, %%rax\n\t"
		"jmp 20f\n\t"
		".p2align 4,,10\n\t"
		".p2align 4\n\t"
		"10:\n\t"
		"movdqu 16(%%rsi), %%xmm8\n\t"
		"cmpq $64, %%rdx\n\t"
		"movdqu %%xmm8, 16(%%rdi)\n\t"
		"movdqu -32(%%rsi,%%rdx), %%xmm8\n\t"
		"movdqu %%xmm8, -32(%%rdi,%%rdx)\n\t"
		"jbe 11b\n\t"
		"movdqu 32(%%rsi), %%xmm8\n\t"
		"cmpq $128, %%rdx\n\t"
		"movdqu %%xmm8, 32(%%rdi)\n\t"
		"movdqu -48(%%rsi,%%rdx), %%xmm8\n\t"
		"movdqu %%xmm8, -48(%%rdi,%%rdx)\n\t"
		"movdqu 48(%%rsi), %%xmm8\n\t"
		"movdqu %%xmm8, 48(%%rdi)\n\t"
		"movdqu -64(%%rsi,%%rdx), %%xmm8\n\t"
		"movdqu %%xmm8, -64(%%rdi,%%rdx)\n\t"
		"jbe 11b\n\t"
		"leaq 64(%%rdi), %%rcx\n\t"
		"addq %%rdi, %%rdx\n\t"
		"andq $-64, %%rdx\n\t"
		"andq $-64, %%rcx\n\t"
		"movq %%rcx, %%rax\n\t"
		"subq %%rdi, %%rax\n\t"
		"addq %%rax, %%rsi\n\t"
		"cmpq %%rdx, %%rcx\n\t"
		"je 11b\n\t"
		"movq %%rsi, %%r10\n\t"
		"subq %%rcx, %%r10\n\t"
		"leaq 16(%%r10), %%r9\n\t"
		"leaq 32(%%r10), %%r8\n\t"
		"leaq 48(%%r10), %%rax\n\t"
		".p2align 4,,10\n\t"
		".p2align 4\n\t"
		"12:\n\t"
		"movdqu (%%rcx,%%r10), %%xmm8\n\t"
		"movdqa %%xmm8, (%%rcx)\n\t"
		"movdqu (%%rcx,%%r9), %%xmm8\n\t"
		"movdqa %%xmm8, 16(%%rcx)\n\t"
		"movdqu (%%rcx,%%r8), %%xmm8\n\t"
		"movdqa %%xmm8, 32(%%rcx)\n\t"
		"movdqu (%%rcx,%%rax), %%xmm8\n\t"
		"movdqa %%xmm8, 48(%%rcx)\n\t"
		"addq $64, %%rcx\n\t"
		"cmpq %%rcx, %%rdx\n\t"
		"jne 12b\n\t"
		"jmp 11b\n\t"
		"8:\n\t"
		"cmpq %%rsi, %%rdi\n\t"
		"jae 13f\n\t"
		"testq %%rdx, %%rdx\n\t"
		".p2align 4,,5\n\t"
		"je 11b\n\t"
		"movq %%rdx, %%r9\n\t"
		"leaq 16(%%rsi), %%rcx\n\t"
		"leaq 16(%%rdi), %%r8\n\t"
		"shrq $4, %%r9\n\t"
		"movq %%r9, %%rax\n\t"
		"salq $4, %%rax\n\t"
		"cmpq %%rcx, %%rdi\n\t"
		"setae %%cl\n\t"
		"cmpq %%r8, %%rsi\n\t"
		"setae %%r8b\n\t"
		"orl %%r8d, %%ecx\n\t"
		"cmpq $15, %%rdx\n\t"
		"seta %%r8b\n\t"
		"testb %%r8b, %%cl\n\t"
		"je 19f\n\t"
		"testq %%rax, %%rax\n\t"
		"je 19f\n\t"
		"xorl %%ecx, %%ecx\n\t"
		"xorl %%r8d, %%r8d\n\t"
		"14:\n\t"
		"movdqu (%%rsi,%%rcx), %%xmm8\n\t"
		"addq $1, %%r8\n\t"
		"movdqu %%xmm8, (%%rdi,%%rcx)\n\t"
		"addq $16, %%rcx\n\t"
		"cmpq %%r8, %%r9\n\t"
		"ja 14b\n\t"
		"cmpq %%rax, %%rdx\n\t"
		"je 11b\n\t"
		"15:\n\t"
		"movzbl (%%rsi,%%rax), %%ecx\n\t"
		"movb %%cl, (%%rdi,%%rax)\n\t"
		"addq $1, %%rax\n\t"
		"cmpq %%rax, %%rdx\n\t"
		"ja 15b\n\t"
		"jmp 11b\n\t"
		"9:\n\t"
		"testb $24, %%dl\n\t"
		"jne 16f\n\t"
		"testb $4, %%dl\n\t"
		".p2align 4,,5\n\t"
		"jne 17f\n\t"
		"testq %%rdx, %%rdx\n\t"
		".p2align 4,,2\n\t"
		"je 11b\n\t"
		"movzbl (%%rsi), %%eax\n\t"
		"testb $2, %%dl\n\t"
		"movb %%al, (%%rdi)\n\t"
		"je 11b\n\t"
		"movzwl -2(%%rsi,%%rdx), %%eax\n\t"
		"movw %%ax, -2(%%rdi,%%rdx)\n\t"
		"jmp 11b\n\t"
		"13:\n\t"
		"leaq -1(%%rdx), %%rax\n\t"
		".p2align 4,,10\n\t"
		".p2align 4\n\t"
		"18:\n\t"
		"movzbl (%%rsi,%%rax), %%edx\n\t"
		"movb %%dl, (%%rdi,%%rax)\n\t"
		"subq $1, %%rax\n\t"
		"jmp 18b\n\t"
		"16:\n\t"
		"movq (%%rsi), %%rax\n\t"
		"movq %%rax, (%%rdi)\n\t"
		"movq -8(%%rsi,%%rdx), %%rax\n\t"
		"movq %%rax, -8(%%rdi,%%rdx)\n\t"
		"jmp 11b\n\t"
		"19:\n\t"
		"xorl %%eax, %%eax\n\t"
		"jmp 15b\n\t"
		"17:\n\t"
		"movl (%%rsi), %%eax\n\t"
		"movl %%eax, (%%rdi)\n\t"
		"movl -4(%%rsi,%%rdx), %%eax\n\t"
		"movl %%eax, -4(%%rdi,%%rdx)\n\t"
		"jmp 11b\n\t"
		"20:\n\t"
		/* scrub registers */
		/* TODO manually audit the above code to see which registers can contain the pointer and thus need to be scrubbed, rather than scrubbing them all */
		"xorq %%rdi, %%rdi\n"
		"xorq %%rsi, %%rsi\n"
		"xorq %%rdx, %%rdx\n"
		"xorq %%rcx, %%rcx\n"
		"pxor %%xmm8, %%xmm8\n"
		"xorq %%r10, %%r10\n"
		"xorq %%r9, %%r9\n"
		"xorq %%r8, %%r8\n"
		: /* no output possible! */ :
		 [destination_offset] "r"(destination_offset),
		 [source] "r"(source), [num] "r"(num)	/* source and num are input operands */
		:"cc", "memory", "%rdi", "%rsi", "%rdx", "%rax", "%rcx", "%xmm8", "%r10", "%r9", "%r8", "%cl", "%ecx", "%dl", "%eax", "%edx"
	);
}

/*-----------------------------------------------------------------------------
    memcmp
-----------------------------------------------------------------------------*/

/* From http://kam.mff.cuni.cz/~ondra/benchmark_string/core2/memcmp_profile/variant/memcmp_new.s */

STATIC INLINE int ipmon_memcmp_ptr_ptr(const void* ptr1, const void* ptr2, size_t num)
{
	int result;
	asm volatile ("movq %[ptr1], %%rdi\n\t"
		"movq %[ptr2], %%rsi\n\t"
		"movq %[num], %%rdx\n\t"
		"testq %%rdx, %%rdx\n\t"
		"je 30f\n\t"
		"pxor %%xmm4, %%xmm4\n\t"
		"movl %%edi, %%eax\n\t"
		"andl $4095, %%eax\n\t"
		"cmpl $4032, %%eax\n\t"
		"jg 27f\n\t"
		"21:\n\t"
		"movl %%esi, %%eax\n\t"
		"andl $4095, %%eax\n\t"
		"cmpl $4032, %%eax\n\t"
		"jg 27f\n\t"
		"movdqu (%%rdi), %%xmm0\n\t"
		"lea -1(%%edx), %%ecx\n\t"
		"movl $2, %%eax\n\t"
		"movdqu (%%rsi), %%xmm1\n\t"
		"salq %%cl, %%rax\n\t"
		"leaq -1(%%rax), %%rcx\n\t"
		"pcmpeqb %%xmm1, %%xmm0\n\t"
		"pcmpeqb %%xmm4, %%xmm0\n\t"
		"pmovmskb %%xmm0, %%eax\n\t"
		"and %%ecx, %%eax\n\t"
		"jne 23f\n\t"
		"cmpq $16, %%rdx\n\t"
		"jbe 30f\n\t"
		"pmovmskb %%xmm0, %%r8d\n\t"
		"movdqu 16(%%rdi), %%xmm2\n\t"
		"movdqu 16(%%rsi), %%xmm6\n\t"
		"movdqu 32(%%rdi), %%xmm1\n\t"
		"pcmpeqb %%xmm6, %%xmm2\n\t"
		"movdqu 32(%%rsi), %%xmm5\n\t"
		"pcmpeqb %%xmm4, %%xmm2\n\t"
		"pcmpeqb %%xmm5, %%xmm1\n\t"
		"movdqu 48(%%rdi), %%xmm7\n\t"
		"pmovmskb %%xmm2, %%eax\n\t"
		"movdqu 48(%%rsi), %%xmm3\n\t"
		"pcmpeqb %%xmm4, %%xmm1\n\t"
		"pmovmskb %%xmm1, %%r9d\n\t"
		"sal $16, %%eax\n\t"
		"pcmpeqb %%xmm3, %%xmm7\n\t"
		"salq $32, %%r9\n\t"
		"pcmpeqb %%xmm4, %%xmm7\n\t"
		"orq %%r9, %%rax\n\t"
		"orq %%r8, %%rax\n\t"
		"pmovmskb %%xmm7, %%r8d\n\t"
		"salq $48, %%r8\n\t"
		"orq %%r8, %%rax\n\t"
		"movq %%rax, %%r8\n\t"
		"andq %%rcx, %%rax\n\t"
		"jne 23f\n\t"
		"cmpq $64, %%rdx\n\t"
		"jbe 30f\n\t"
		"movq %%r8, %%rax\n\t"
		"testq %%rax, %%rax\n\t"
		"jne 23f\n\t"
		"22:\n\t"
		"leaq 64(%%rdi), %%rax\n\t"
		"andq $-64, %%rax\n\t"
		"subq %%rdi, %%rax\n\t"
		"subq %%rax, %%rdx\n\t"
		"addq %%rax, %%rdi\n\t"
		"addq %%rax, %%rsi\n\t"
		"cmpq $64, %%rdx\n\t"
		"ja 25f\n\t"
		"testq %%rdx, %%rdx\n\t"
		"jne 21b\n\t"
		"xorl %%eax, %%eax\n\t"
		"jmp 32f\n\t"
		".p2align 4\n\t"
		"23:\n\t"
		"bsfq %%rax, %%rdx\n\t"
		"movzbl (%%rdi,%%rdx), %%eax\n\t"
		"movzbl (%%rsi,%%rdx), %%edx\n\t"
		"subl %%edx, %%eax\n\t"
		"jmp 32f\n\t"
		".p2align 4\n\t"
		"24:\n\t"
		"subq $64, %%rdx\n\t"
		"addq $64, %%rdi\n\t"
		"addq $64, %%rsi\n\t"
		"cmpq $64, %%rdx\n\t"
		"jbe 26f\n\t"
		"25:\n\t"
		"movdqu (%%rsi), %%xmm0\n\t"
		"movdqu 16(%%rsi), %%xmm1\n\t"
		"pcmpeqb (%%rdi), %%xmm0\n\t"
		"movdqu 32(%%rsi), %%xmm2\n\t"
		"pcmpeqb 16(%%rdi), %%xmm1\n\t"
		"movdqu 48(%%rsi), %%xmm3\n\t"
		"pcmpeqb 32(%%rdi), %%xmm2\n\t"
		"pcmpeqb 48(%%rdi), %%xmm3\n\t"
		"pminub %%xmm0, %%xmm3\n\t"
		"pminub %%xmm1, %%xmm3\n\t"
		"pminub %%xmm2, %%xmm3\n\t"
		"pcmpeqb %%xmm4, %%xmm3\n\t"
		"pmovmskb %%xmm3, %%eax\n\t"
		"testl %%eax, %%eax\n\t"
		"je 24b\n\t"
		"shl $48, %%rax\n\t"
		"pcmpeqb %%xmm4, %%xmm0\n\t"
		"pcmpeqb %%xmm4, %%xmm1\n\t"
		"pcmpeqb %%xmm4, %%xmm2\n\t"
		"pmovmskb %%xmm0, %%r8\n\t"
		"pmovmskb %%xmm1, %%rcx\n\t"
		"pmovmskb %%xmm2, %%r9\n\t"
		"shl $16, %%ecx\n\t"
		"shl $32, %%r9\n\t"
		"or %%r8, %%rax\n\t"
		"or %%r9, %%rax\n\t"
		"or %%rcx, %%rax\n\t"
		"jmp 23b\n\t"
		".p2align 4\n\t"
		"26:\n\t"
		"testq %%rdx, %%rdx\n\t"
		"jne 21b\n\t"
		"xorl %%eax, %%eax\n\t"
		"jmp 32f\n\t"
		".p2align 4\n\t"
		"27:\n\t"
		"testq %%rdx, %%rdx\n\t"
		"je 30f\n\t"
		"movzbl (%%rdi), %%eax\n\t"
		"movzbl (%%rsi), %%ecx\n\t"
		"cmpb %%cl, %%al\n\t"
		"jne 31f\n\t"
		"movl $1, %%r8d\n\t"
		"jmp 29f\n\t"
		".p2align 4\n\t"
		"28:\n\t"
		"movzbl (%%rdi,%%r8), %%eax\n\t"
		"movzbl (%%rsi,%%r8), %%ecx\n\t"
		"cmpb %%cl, %%al\n\t"
		"jne 31f\n\t"
		"addq $1, %%r8\n\t"
		"cmpq $65, %%r8\n\t"
		"je 22b\n\t"
		"29:\n\t"
		"cmpq %%rdx, %%r8\n\t"
		"jne 28b\n\t"
		"30:\n\t"
		"xorl %%eax, %%eax\n\t"
		"jmp 32f\n\t"
		"31:\n\t"
		"subl %%ecx, %%eax\n\t"
		"32:\n\t"
		"movl %%eax, %[result]"
		: [result] "=r"(result)/* result is output operands */
		: [ptr1] "r"(ptr1), [ptr2] "r"(ptr2), [num] "r"(num) /* ptr1, ptr2 and num are input operands */
		: "cc", "memory", "%eax", "%r8", "%al", "%ecx", "%rdx", "%rax", "%r9", "%rcx", "%xmm2", "%xmm1", "%xmm0", "%xmm3", "%rsi", "%rdi", "%edx", "%xmm7", "%xmm5", "%xmm6", "%xmm4"
	);

	return result;
}

/*---------------------------------------------------------------------------*/

STATIC INLINE int ipmon_memcmp_ptr_offset(const void* ptr1, unsigned long ptr2_offset, size_t num)
{
	int result;
	asm volatile ("movq %[ptr1], %%rdi\n\t"
		"leaq (%%" RB_REGISTER ", %[ptr2_offset]), %%rsi\n\t"	/* rsi tainted! */
		"movq %[num], %%rdx\n\t"
		"testq %%rdx, %%rdx\n\t"
		"je 30f\n\t"
		"pxor %%xmm4, %%xmm4\n\t"
		"movl %%edi, %%eax\n\t"
		"andl $4095, %%eax\n\t"
		"cmpl $4032, %%eax\n\t"
		"jg 27f\n\t"
		"21:\n\t"
		"movl %%esi, %%eax\n\t"
		"andl $4095, %%eax\n\t"
		"cmpl $4032, %%eax\n\t"
		"jg 27f\n\t"
		"movdqu (%%rdi), %%xmm0\n\t"
		"lea -1(%%edx), %%ecx\n\t"
		"movl $2, %%eax\n\t"
		"movdqu (%%rsi), %%xmm1\n\t"
		"salq %%cl, %%rax\n\t"
		"leaq -1(%%rax), %%rcx\n\t"
		"pcmpeqb %%xmm1, %%xmm0\n\t"
		"pcmpeqb %%xmm4, %%xmm0\n\t"
		"pmovmskb %%xmm0, %%eax\n\t"
		"and %%ecx, %%eax\n\t"
		"jne 23f\n\t"
		"cmpq $16, %%rdx\n\t"
		"jbe 30f\n\t"
		"pmovmskb %%xmm0, %%r8d\n\t"
		"movdqu 16(%%rdi), %%xmm2\n\t"
		"movdqu 16(%%rsi), %%xmm6\n\t"
		"movdqu 32(%%rdi), %%xmm1\n\t"
		"pcmpeqb %%xmm6, %%xmm2\n\t"
		"movdqu 32(%%rsi), %%xmm5\n\t"
		"pcmpeqb %%xmm4, %%xmm2\n\t"
		"pcmpeqb %%xmm5, %%xmm1\n\t"
		"movdqu 48(%%rdi), %%xmm7\n\t"
		"pmovmskb %%xmm2, %%eax\n\t"
		"movdqu 48(%%rsi), %%xmm3\n\t"
		"pcmpeqb %%xmm4, %%xmm1\n\t"
		"pmovmskb %%xmm1, %%r9d\n\t"
		"sal $16, %%eax\n\t"
		"pcmpeqb %%xmm3, %%xmm7\n\t"
		"salq $32, %%r9\n\t"
		"pcmpeqb %%xmm4, %%xmm7\n\t"
		"orq %%r9, %%rax\n\t"
		"orq %%r8, %%rax\n\t"
		"pmovmskb %%xmm7, %%r8d\n\t"
		"salq $48, %%r8\n\t"
		"orq %%r8, %%rax\n\t"
		"movq %%rax, %%r8\n\t"
		"andq %%rcx, %%rax\n\t"
		"jne 23f\n\t"
		"cmpq $64, %%rdx\n\t"
		"jbe 30f\n\t"
		"movq %%r8, %%rax\n\t"
		"testq %%rax, %%rax\n\t"
		"jne 23f\n\t"
		"22:\n\t"
		"leaq 64(%%rdi), %%rax\n\t"
		"andq $-64, %%rax\n\t"
		"subq %%rdi, %%rax\n\t"
		"subq %%rax, %%rdx\n\t"
		"addq %%rax, %%rdi\n\t"
		"addq %%rax, %%rsi\n\t"
		"cmpq $64, %%rdx\n\t"
		"ja 25f\n\t"
		"testq %%rdx, %%rdx\n\t"
		"jne 21b\n\t"
		"xorl %%eax, %%eax\n\t"
		"jmp 32f\n\t"
		".p2align 4\n\t"
		"23:\n\t"
		"bsfq %%rax, %%rdx\n\t"
		"movzbl (%%rdi,%%rdx), %%eax\n\t"
		"movzbl (%%rsi,%%rdx), %%edx\n\t"
		"subl %%edx, %%eax\n\t"
		"jmp 32f\n\t"
		".p2align 4\n\t"
		"24:\n\t"
		"subq $64, %%rdx\n\t"
		"addq $64, %%rdi\n\t"
		"addq $64, %%rsi\n\t"
		"cmpq $64, %%rdx\n\t"
		"jbe 26f\n\t"
		"25:\n\t"
		"movdqu (%%rsi), %%xmm0\n\t"
		"movdqu 16(%%rsi), %%xmm1\n\t"
		"pcmpeqb (%%rdi), %%xmm0\n\t"
		"movdqu 32(%%rsi), %%xmm2\n\t"
		"pcmpeqb 16(%%rdi), %%xmm1\n\t"
		"movdqu 48(%%rsi), %%xmm3\n\t"
		"pcmpeqb 32(%%rdi), %%xmm2\n\t"
		"pcmpeqb 48(%%rdi), %%xmm3\n\t"
		"pminub %%xmm0, %%xmm3\n\t"
		"pminub %%xmm1, %%xmm3\n\t"
		"pminub %%xmm2, %%xmm3\n\t"
		"pcmpeqb %%xmm4, %%xmm3\n\t"
		"pmovmskb %%xmm3, %%eax\n\t"
		"testl %%eax, %%eax\n\t"
		"je 24b\n\t"
		"shl $48, %%rax\n\t"
		"pcmpeqb %%xmm4, %%xmm0\n\t"
		"pcmpeqb %%xmm4, %%xmm1\n\t"
		"pcmpeqb %%xmm4, %%xmm2\n\t"
		"pmovmskb %%xmm0, %%r8\n\t"
		"pmovmskb %%xmm1, %%rcx\n\t"
		"pmovmskb %%xmm2, %%r9\n\t"
		"shl $16, %%ecx\n\t"
		"shl $32, %%r9\n\t"
		"or %%r8, %%rax\n\t"
		"or %%r9, %%rax\n\t"
		"or %%rcx, %%rax\n\t"
		"jmp 23b\n\t"
		".p2align 4\n\t"
		"26:\n\t"
		"testq %%rdx, %%rdx\n\t"
		"jne 21b\n\t"
		"xorl %%eax, %%eax\n\t"
		"jmp 32f\n\t"
		".p2align 4\n\t"
		"27:\n\t"
		"testq %%rdx, %%rdx\n\t"
		"je 30f\n\t"
		"movzbl (%%rdi), %%eax\n\t"
		"movzbl (%%rsi), %%ecx\n\t"
		"cmpb %%cl, %%al\n\t"
		"jne 31f\n\t"
		"movl $1, %%r8d\n\t"
		"jmp 29f\n\t"
		".p2align 4\n\t"
		"28:\n\t"
		"movzbl (%%rdi,%%r8), %%eax\n\t"
		"movzbl (%%rsi,%%r8), %%ecx\n\t"
		"cmpb %%cl, %%al\n\t"
		"jne 31f\n\t"
		"addq $1, %%r8\n\t"
		"cmpq $65, %%r8\n\t"
		"je 22b\n\t"
		"29:\n\t"
		"cmpq %%rdx, %%r8\n\t"
		"jne 28b\n\t"
		"30:\n\t"
		"xorl %%eax, %%eax\n\t"
		"jmp 32f\n\t"
		"31:\n\t"
		"subl %%ecx, %%eax\n\t"
		"32:\n\t"
		/* scrub registers */
		/* TODO manually audit the above code to see which registers can contain the pointer and thus need to be scrubbed, rather than scrubbing them all */
		"xorq %%rdi, %%rdi\n"
		"xorq %%rsi, %%rsi\n"
		"xorq %%rdx, %%rdx\n"
		"xorq %%rcx, %%rcx\n"
		"pxor %%xmm0, %%xmm0\n"
		"pxor %%xmm1, %%xmm1\n"
		"pxor %%xmm2, %%xmm2\n"
		"pxor %%xmm3, %%xmm3\n"
		"pxor %%xmm4, %%xmm4\n"
		"pxor %%xmm5, %%xmm5\n"
		"pxor %%xmm6, %%xmm6\n"
		"pxor %%xmm7, %%xmm7\n"
		"xorq %%r9, %%r9\n"
		"xorq %%r8, %%r8\n"

		"movl %%eax, %[result]"
		: [result] "=r"(result)/* result is output operands */
		: [ptr1] "r"(ptr1), [ptr2_offset] "r"(ptr2_offset), [num] "r"(num) /* ptr1, ptr2 and num are input operands */
		: "cc", "memory", "%eax", "%r8", "%al", "%ecx", "%rdx", "%rax", "%r9", "%rcx", "%xmm2", "%xmm1", "%xmm0", "%xmm3", "%rsi", "%rdi", "%edx", "%xmm7", "%xmm5", "%xmm6", "%xmm4"
	);

	return result;
}

/*---------------------------------------------------------------------------*/

STATIC INLINE int ipmon_memcmp_offset_ptr(unsigned long ptr1_offset, const void * ptr2, size_t num)
{
	int result;
	asm volatile ("leaq (%%" RB_REGISTER ", %[ptr1_offset]), %%rdi\n\t"	/* rdi tainted! */
		"movq %[ptr2], %%rsi\n\t"
		"movq %[num], %%rdx\n\t"
		"testq %%rdx, %%rdx\n\t"
		"je 30f\n\t"
		"pxor %%xmm4, %%xmm4\n\t"
		"movl %%edi, %%eax\n\t"
		"andl $4095, %%eax\n\t"
		"cmpl $4032, %%eax\n\t"
		"jg 27f\n\t"
		"21:\n\t"
		"movl %%esi, %%eax\n\t"
		"andl $4095, %%eax\n\t"
		"cmpl $4032, %%eax\n\t"
		"jg 27f\n\t"
		"movdqu (%%rdi), %%xmm0\n\t"
		"lea -1(%%edx), %%ecx\n\t"
		"movl $2, %%eax\n\t"
		"movdqu (%%rsi), %%xmm1\n\t"
		"salq %%cl, %%rax\n\t"
		"leaq -1(%%rax), %%rcx\n\t"
		"pcmpeqb %%xmm1, %%xmm0\n\t"
		"pcmpeqb %%xmm4, %%xmm0\n\t"
		"pmovmskb %%xmm0, %%eax\n\t"
		"and %%ecx, %%eax\n\t"
		"jne 23f\n\t"
		"cmpq $16, %%rdx\n\t"
		"jbe 30f\n\t"
		"pmovmskb %%xmm0, %%r8d\n\t"
		"movdqu 16(%%rdi), %%xmm2\n\t"
		"movdqu 16(%%rsi), %%xmm6\n\t"
		"movdqu 32(%%rdi), %%xmm1\n\t"
		"pcmpeqb %%xmm6, %%xmm2\n\t"
		"movdqu 32(%%rsi), %%xmm5\n\t"
		"pcmpeqb %%xmm4, %%xmm2\n\t"
		"pcmpeqb %%xmm5, %%xmm1\n\t"
		"movdqu 48(%%rdi), %%xmm7\n\t"
		"pmovmskb %%xmm2, %%eax\n\t"
		"movdqu 48(%%rsi), %%xmm3\n\t"
		"pcmpeqb %%xmm4, %%xmm1\n\t"
		"pmovmskb %%xmm1, %%r9d\n\t"
		"sal $16, %%eax\n\t"
		"pcmpeqb %%xmm3, %%xmm7\n\t"
		"salq $32, %%r9\n\t"
		"pcmpeqb %%xmm4, %%xmm7\n\t"
		"orq %%r9, %%rax\n\t"
		"orq %%r8, %%rax\n\t"
		"pmovmskb %%xmm7, %%r8d\n\t"
		"salq $48, %%r8\n\t"
		"orq %%r8, %%rax\n\t"
		"movq %%rax, %%r8\n\t"
		"andq %%rcx, %%rax\n\t"
		"jne 23f\n\t"
		"cmpq $64, %%rdx\n\t"
		"jbe 30f\n\t"
		"movq %%r8, %%rax\n\t"
		"testq %%rax, %%rax\n\t"
		"jne 23f\n\t"
		"22:\n\t"
		"leaq 64(%%rdi), %%rax\n\t"
		"andq $-64, %%rax\n\t"
		"subq %%rdi, %%rax\n\t"
		"subq %%rax, %%rdx\n\t"
		"addq %%rax, %%rdi\n\t"
		"addq %%rax, %%rsi\n\t"
		"cmpq $64, %%rdx\n\t"
		"ja 25f\n\t"
		"testq %%rdx, %%rdx\n\t"
		"jne 21b\n\t"
		"xorl %%eax, %%eax\n\t"
		"jmp 32f\n\t"
		".p2align 4\n\t"
		"23:\n\t"
		"bsfq %%rax, %%rdx\n\t"
		"movzbl (%%rdi,%%rdx), %%eax\n\t"
		"movzbl (%%rsi,%%rdx), %%edx\n\t"
		"subl %%edx, %%eax\n\t"
		"jmp 32f\n\t"
		".p2align 4\n\t"
		"24:\n\t"
		"subq $64, %%rdx\n\t"
		"addq $64, %%rdi\n\t"
		"addq $64, %%rsi\n\t"
		"cmpq $64, %%rdx\n\t"
		"jbe 26f\n\t"
		"25:\n\t"
		"movdqu (%%rsi), %%xmm0\n\t"
		"movdqu 16(%%rsi), %%xmm1\n\t"
		"pcmpeqb (%%rdi), %%xmm0\n\t"
		"movdqu 32(%%rsi), %%xmm2\n\t"
		"pcmpeqb 16(%%rdi), %%xmm1\n\t"
		"movdqu 48(%%rsi), %%xmm3\n\t"
		"pcmpeqb 32(%%rdi), %%xmm2\n\t"
		"pcmpeqb 48(%%rdi), %%xmm3\n\t"
		"pminub %%xmm0, %%xmm3\n\t"
		"pminub %%xmm1, %%xmm3\n\t"
		"pminub %%xmm2, %%xmm3\n\t"
		"pcmpeqb %%xmm4, %%xmm3\n\t"
		"pmovmskb %%xmm3, %%eax\n\t"
		"testl %%eax, %%eax\n\t"
		"je 24b\n\t"
		"shl $48, %%rax\n\t"
		"pcmpeqb %%xmm4, %%xmm0\n\t"
		"pcmpeqb %%xmm4, %%xmm1\n\t"
		"pcmpeqb %%xmm4, %%xmm2\n\t"
		"pmovmskb %%xmm0, %%r8\n\t"
		"pmovmskb %%xmm1, %%rcx\n\t"
		"pmovmskb %%xmm2, %%r9\n\t"
		"shl $16, %%ecx\n\t"
		"shl $32, %%r9\n\t"
		"or %%r8, %%rax\n\t"
		"or %%r9, %%rax\n\t"
		"or %%rcx, %%rax\n\t"
		"jmp 23b\n\t"
		".p2align 4\n\t"
		"26:\n\t"
		"testq %%rdx, %%rdx\n\t"
		"jne 21b\n\t"
		"xorl %%eax, %%eax\n\t"
		"jmp 32f\n\t"
		".p2align 4\n\t"
		"27:\n\t"
		"testq %%rdx, %%rdx\n\t"
		"je 30f\n\t"
		"movzbl (%%rdi), %%eax\n\t"
		"movzbl (%%rsi), %%ecx\n\t"
		"cmpb %%cl, %%al\n\t"
		"jne 31f\n\t"
		"movl $1, %%r8d\n\t"
		"jmp 29f\n\t"
		".p2align 4\n\t"
		"28:\n\t"
		"movzbl (%%rdi,%%r8), %%eax\n\t"
		"movzbl (%%rsi,%%r8), %%ecx\n\t"
		"cmpb %%cl, %%al\n\t"
		"jne 31f\n\t"
		"addq $1, %%r8\n\t"
		"cmpq $65, %%r8\n\t"
		"je 22b\n\t"
		"29:\n\t"
		"cmpq %%rdx, %%r8\n\t"
		"jne 28b\n\t"
		"30:\n\t"
		"xorl %%eax, %%eax\n\t"
		"jmp 32f\n\t"
		"31:\n\t"
		"subl %%ecx, %%eax\n\t"
		"32:\n\t"
		/* scrub registers */
		/* TODO manually audit the above code to see which registers can contain the pointer and thus need to be scrubbed, rather than scrubbing them all */
		"xorq %%rdi, %%rdi\n"
		"xorq %%rsi, %%rsi\n"
		"xorq %%rdx, %%rdx\n"
		"xorq %%rcx, %%rcx\n"
		"pxor %%xmm0, %%xmm0\n"
		"pxor %%xmm1, %%xmm1\n"
		"pxor %%xmm2, %%xmm2\n"
		"pxor %%xmm3, %%xmm3\n"
		"pxor %%xmm4, %%xmm4\n"
		"pxor %%xmm5, %%xmm5\n"
		"pxor %%xmm6, %%xmm6\n"
		"pxor %%xmm7, %%xmm7\n"
		"xorq %%r9, %%r9\n"
		"xorq %%r8, %%r8\n"

		"movl %%eax, %[result]"
		: [result] "=r"(result)/* result is output operands */
		: [ptr1_offset] "r"(ptr1_offset), [ptr2] "r"(ptr2), [num] "r"(num) /* ptr1, ptr2 and num are input operands */
		: "cc", "memory", "%eax", "%r8", "%al", "%ecx", "%rdx", "%rax", "%r9", "%rcx", "%xmm2", "%xmm1", "%xmm0", "%xmm3", "%rsi", "%rdi", "%edx", "%xmm7", "%xmm5", "%xmm6", "%xmm4"
	);

	return result;
}

/*-----------------------------------------------------------------------------
    memset
-----------------------------------------------------------------------------*/

/* From glibc */

STATIC INLINE void ipmon_memset_ptr(void* ptr, int value, size_t num)
{
	asm volatile("movq %[ptr], %%rdi\n\t"
		"movl %[value], %%esi\n\t"
		"movq %[num], %%rdx\n\t"
		"movd %%esi, %%xmm8\n\t"
		"movq %%rdi, %%rax\n\t"
		"punpcklbw %%xmm8, %%xmm8\n\t"
		"punpcklwd %%xmm8, %%xmm8\n\t"
		"pshufd $0, %%xmm8, %%xmm8\n\t"
		"33:\n\t"
		"cmpq $64, %%rdx\n\t"
		"ja 36f\n\t"
		"cmpq $16, %%rdx\n\t"
		"jbe 38f\n\t"
		"cmpq $32, %%rdx\n\t"
		"movdqu %%xmm8, (%%rdi)\n\t"
		"movdqu %%xmm8, -16(%%rdi,%%rdx)\n\t"
		"ja 35f\n\t"
		"34:\n\t"
		"rep\n\t"
		"jmp 42f\n\t"
		".p2align 4\n\t"
		"35:\n\t"
		"movdqu %%xmm8, 16(%%rdi)\n\t"
		"movdqu %%xmm8, -32(%%rdi,%%rdx)\n\t"
		"jmp 42f\n\t"
		".p2align 4\n\t"
		"36:\n\t"
		"leaq 64(%%rdi), %%rcx\n\t"
		"movdqu %%xmm8, (%%rdi)\n\t"
		"andq $-64, %%rcx\n\t"
		"movdqu %%xmm8, -16(%%rdi,%%rdx)\n\t"
		"movdqu %%xmm8, 16(%%rdi)\n\t"
		"movdqu %%xmm8, -32(%%rdi,%%rdx)\n\t"
		"movdqu %%xmm8, 32(%%rdi)\n\t"
		"movdqu %%xmm8, -48(%%rdi,%%rdx)\n\t"
		"movdqu %%xmm8, 48(%%rdi)\n\t"
		"movdqu %%xmm8, -64(%%rdi,%%rdx)\n\t"
		"addq %%rdi, %%rdx\n\t"
		"andq $-64, %%rdx\n\t"
		"cmpq %%rdx, %%rcx\n\t"
		"je 34b\n\t"
		".p2align 4\n\t"
		"37:\n\t"
		"movdqa %%xmm8, (%%rcx)\n\t"
		"movdqa %%xmm8, 16(%%rcx)\n\t"
		"movdqa %%xmm8, 32(%%rcx)\n\t"
		"movdqa %%xmm8, 48(%%rcx)\n\t"
		"addq $64, %%rcx\n\t"
		"cmpq %%rcx, %%rdx\n\t"
		"jne 37b\n\t"
		"rep\n\t"
		"jmp 42f\n\t"
		"38:\n\t"
		"movq %%xmm8, %%rcx\n\t"
		"testb $24, %%dl\n\t"
		"jne 41f\n\t"
		"testb $4, %%dl\n\t"
		"jne 40f\n\t"
		"testb $1, %%dl\n\t"
		"je 39f\n\t"
		"movb %%cl, (%%rdi)\n\t"
		"39:\n\t"
		"testb $2, %%dl\n\t"
		"je 34b\n\t"
		"movw %%cx, -2(%%rax,%%rdx)\n\t"
		"jmp 42f\n\t"
		"40:\n\t"
		"movl %%ecx, (%%rdi)\n\t"
		"movl %%ecx, -4(%%rdi,%%rdx)\n\t"
		"jmp 42f\n\t"
		"41:\n\t"
		"movq %%rcx, (%%rdi)\n\t"
		"movq %%rcx, -8(%%rdi,%%rdx)\n\t"
		"42:"
		:            // no output operand
		: [ptr] "r" (ptr), [value] "r"(value), [num] "r"(num) // input operands
		: "cc", "memory", "%dl", "%rcx", "%rdx", "%xmm8", "%esi", "%rdi", "%rax", "%rsi"
	);
}

STATIC INLINE void ipmon_memset_offset(unsigned long offset, int value, size_t num)
{
	asm volatile("leaq (%%" RB_REGISTER ", %[offset]), %%rdi\n\t"	/* rdi tainted! */
		"movl %[value], %%esi\n\t"
		"movq %[num], %%rdx\n\t"
		"movd %%esi, %%xmm8\n\t"
		"movq %%rdi, %%rax\n\t"									/* rax tained! */
		"punpcklbw %%xmm8, %%xmm8\n\t"
		"punpcklwd %%xmm8, %%xmm8\n\t"
		"pshufd $0, %%xmm8, %%xmm8\n\t"
		"33:\n\t"
		"cmpq $64, %%rdx\n\t"
		"ja 36f\n\t"
		"cmpq $16, %%rdx\n\t"
		"jbe 38f\n\t"
		"cmpq $32, %%rdx\n\t"
		"movdqu %%xmm8, (%%rdi)\n\t"
		"movdqu %%xmm8, -16(%%rdi,%%rdx)\n\t"
		"ja 35f\n\t"
		"34:\n\t"
		"rep\n\t"
		"jmp 42f\n\t"
		".p2align 4\n\t"
		"35:\n\t"
		"movdqu %%xmm8, 16(%%rdi)\n\t"
		"movdqu %%xmm8, -32(%%rdi,%%rdx)\n\t"
		"jmp 42f\n\t"
		".p2align 4\n\t"
		"36:\n\t"
		"leaq 64(%%rdi), %%rcx\n\t"								/* rcx tainted! */
		"movdqu %%xmm8, (%%rdi)\n\t"
		"andq $-64, %%rcx\n\t"
		"movdqu %%xmm8, -16(%%rdi,%%rdx)\n\t"
		"movdqu %%xmm8, 16(%%rdi)\n\t"
		"movdqu %%xmm8, -32(%%rdi,%%rdx)\n\t"
		"movdqu %%xmm8, 32(%%rdi)\n\t"
		"movdqu %%xmm8, -48(%%rdi,%%rdx)\n\t"
		"movdqu %%xmm8, 48(%%rdi)\n\t"
		"movdqu %%xmm8, -64(%%rdi,%%rdx)\n\t"
		"addq %%rdi, %%rdx\n\t"									/* rdx tainted! */
		"andq $-64, %%rdx\n\t"
		"cmpq %%rdx, %%rcx\n\t"
		"je 34b\n\t"
		".p2align 4\n\t"
		"37:\n\t"
		"movdqa %%xmm8, (%%rcx)\n\t"
		"movdqa %%xmm8, 16(%%rcx)\n\t"
		"movdqa %%xmm8, 32(%%rcx)\n\t"
		"movdqa %%xmm8, 48(%%rcx)\n\t"
		"addq $64, %%rcx\n\t"
		"cmpq %%rcx, %%rdx\n\t"
		"jne 37b\n\t"
		"rep\n\t"
		"jmp 42f\n\t"
		"38:\n\t"
		"movq %%xmm8, %%rcx\n\t"
		"testb $24, %%dl\n\t"
		"jne 41f\n\t"
		"testb $4, %%dl\n\t"
		"jne 40f\n\t"
		"testb $1, %%dl\n\t"
		"je 39f\n\t"
		"movb %%cl, (%%rdi)\n\t"
		"39:\n\t"
		"testb $2, %%dl\n\t"
		"je 34b\n\t"
		"movw %%cx, -2(%%rax,%%rdx)\n\t"
		"jmp 42f\n\t"
		"40:\n\t"
		"movl %%ecx, (%%rdi)\n\t"
		"movl %%ecx, -4(%%rdi,%%rdx)\n\t"
		"jmp 42f\n\t"
		"41:\n\t"
		"movq %%rcx, (%%rdi)\n\t"
		"movq %%rcx, -8(%%rdi,%%rdx)\n\t"
		"42:"
		/* scrub tainted registers */
		"xorq %%rax, %%rax\n"									/* rax ok */
		"xorq %%rdi, %%rdi\n"									/* rdi ok */
		"xorq %%rcx, %%rcx\n"									/* rcx ok */
		"xorq %%rdx, %%rdx\n"									/* rdx ok */
		:            // no output operand
		: [offset] "r" (offset), [value] "r"(value), [num] "r"(num) // input operands
		: "cc", "memory", "%dl", "%rcx", "%rdx", "%xmm8", "%esi", "%rdi", "%rax", "%rsi"
	);
}


#endif /* IPMON_INLINES_H_ */
